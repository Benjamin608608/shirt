#!/usr/bin/env node

/**
 * Supabase åç«¯è‡ªåŠ¨è®¾ç½®è„šæœ¬
 *
 * ä½¿ç”¨æ–¹æ³•:
 * 1. è®¾ç½®ç¯å¢ƒå˜é‡:
 *    export SUPABASE_URL="ä½ çš„ Supabase URL"
 *    export SUPABASE_SERVICE_KEY="ä½ çš„æœåŠ¡å¯†é’¥"
 *
 * 2. è¿è¡Œè„šæœ¬:
 *    node scripts/setup-backend.js
 */

const fs = require('fs');
const path = require('path');
const { createClient } = require('@supabase/supabase-js');

// é¢œè‰²è¾“å‡º
const colors = {
  reset: '\x1b[0m',
  green: '\x1b[32m',
  red: '\x1b[31m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
};

function log(message, color = 'reset') {
  console.log(`${colors[color]}${message}${colors.reset}`);
}

async function setupBackend() {
  log('\nğŸš€ å¼€å§‹è®¾ç½® Supabase åç«¯...\n', 'blue');

  // æ£€æŸ¥ç¯å¢ƒå˜é‡
  const SUPABASE_URL = process.env.SUPABASE_URL;
  const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_KEY;

  if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY) {
    log('âŒ é”™è¯¯ï¼šç¼ºå°‘ç¯å¢ƒå˜é‡', 'red');
    log('\nè¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:', 'yellow');
    log('  export SUPABASE_URL="ä½ çš„ Supabase URL"', 'yellow');
    log('  export SUPABASE_SERVICE_KEY="ä½ çš„æœåŠ¡å¯†é’¥"\n', 'yellow');
    process.exit(1);
  }

  // åˆ›å»º Supabase å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨æœåŠ¡å¯†é’¥ï¼‰
  const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY);

  try {
    // è¯»å– migration æ–‡ä»¶
    const migrationsDir = path.join(__dirname, '../supabase/migrations');
    const migrations = [
      '001_initial_schema.sql',
      '002_virtual_tryon.sql',
      '003_storage_setup.sql',
    ];

    // æ‰§è¡Œæ¯ä¸ª migration
    for (const migrationFile of migrations) {
      const filePath = path.join(migrationsDir, migrationFile);

      log(`\nğŸ“ æ‰§è¡Œ ${migrationFile}...`, 'blue');

      if (!fs.existsSync(filePath)) {
        log(`  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: ${filePath}`, 'yellow');
        continue;
      }

      const sql = fs.readFileSync(filePath, 'utf8');

      // ä½¿ç”¨ RPC æ‰§è¡Œ SQL
      const { data, error } = await supabase.rpc('exec_sql', { sql_string: sql });

      if (error) {
        // æŸäº›é”™è¯¯æ˜¯å¯ä»¥æ¥å—çš„ï¼ˆæ¯”å¦‚ "already exists"ï¼‰
        if (error.message.includes('already exists')) {
          log(`  âœ… ${migrationFile} - å·²å­˜åœ¨ï¼Œè·³è¿‡`, 'yellow');
        } else {
          log(`  âŒ é”™è¯¯: ${error.message}`, 'red');
        }
      } else {
        log(`  âœ… ${migrationFile} - æ‰§è¡ŒæˆåŠŸ`, 'green');
      }
    }

    // éªŒè¯è®¾ç½®
    log('\n\nğŸ” éªŒè¯è®¾ç½®...', 'blue');

    // æ£€æŸ¥ buckets
    const { data: buckets, error: bucketsError } = await supabase
      .storage
      .listBuckets();

    if (bucketsError) {
      log(`  âŒ æ— æ³•è·å– buckets: ${bucketsError.message}`, 'red');
    } else {
      const expectedBuckets = ['garments', 'user-photos', 'tryon-results'];
      const existingBuckets = buckets.map(b => b.name);

      log('\nğŸ“¦ Storage Buckets:', 'blue');
      expectedBuckets.forEach(name => {
        if (existingBuckets.includes(name)) {
          log(`  âœ… ${name}`, 'green');
        } else {
          log(`  âŒ ${name} - æœªæ‰¾åˆ°`, 'red');
        }
      });
    }

    // æ£€æŸ¥è¡¨
    log('\nğŸ“Š æ•°æ®åº“è¡¨:', 'blue');
    const tables = ['garments', 'user_photos', 'tryon_jobs'];

    for (const table of tables) {
      const { data, error } = await supabase
        .from(table)
        .select('id')
        .limit(0);

      if (error && !error.message.includes('0 rows')) {
        log(`  âŒ ${table} - ${error.message}`, 'red');
      } else {
        log(`  âœ… ${table}`, 'green');
      }
    }

    log('\n\nâœ¨ è®¾ç½®å®Œæˆï¼', 'green');
    log('\nä¸‹ä¸€æ­¥:', 'blue');
    log('  1. è¿è¡Œåº”ç”¨: npm start', 'yellow');
    log('  2. æµ‹è¯•ä¸Šä¼ è¡£ç‰©åŠŸèƒ½', 'yellow');
    log('  3. æµ‹è¯•ä¸Šä¼ ä¸ªäººç…§ç‰‡åŠŸèƒ½\n', 'yellow');

  } catch (error) {
    log(`\nâŒ è®¾ç½®å¤±è´¥: ${error.message}`, 'red');
    console.error(error);
    process.exit(1);
  }
}

// è¿è¡Œè®¾ç½®
setupBackend();
